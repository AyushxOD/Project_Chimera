# =============================================================================
# Cell 1: Import Libraries & Setup
# =============================================================================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier

# Set plot style
sns.set_style("whitegrid")
print("Libraries imported successfully.")


# =============================================================================
# Cell 2: Load the Dataset
# =============================================================================
# Load the data from the CSV file located in the 'data' sub-folder
df = pd.read_csv('../data/Master_Target_List.csv')

print("Dataset loaded successfully. Here's a preview:")
print(df.head())


# =============================================================================
# Cell 3: Data Cleaning & Augmentation (for demonstration)
# =============================================================================
# In a real project, this data would be collected. For this notebook,
# we'll generate some plausible random data for the missing columns.
np.random.seed(42) # for reproducible results
df['Patent_Citation_Velocity'] = np.random.uniform(5, 20, df.shape[0]) * (df['Investor_Quality_Score'] / 2)
df['Time_Since_Last_Funding'] = np.random.randint(6, 36, df.shape[0])
df['Glassdoor_Rating'] = np.random.uniform(3.5, 4.8, df.shape[0]).round(1)

print("\nAugmented data with simulated columns:")
print(df.head())


# =============================================================================
# Cell 4: Exploratory Data Analysis (EDA) - Funding Distribution
# =============================================================================
plt.figure(figsize=(10, 6))
sns.histplot(df['Total_Funding_USD_M'], bins=15, kde=True)
plt.title('Funding Distribution: A Few Companies Dominate', fontsize=16)
plt.xlabel('Total Funding in Millions (USD)')
plt.ylabel('Number of Companies')
plt.show()
print("EDA Insight 1: The funding follows a power law, with a few startups like Cerebras raising a majority of the capital.")


# =============================================================================
# Cell 5: EDA - The Innovation vs. Hype Matrix
# =============================================================================
plt.figure(figsize=(12, 8))
sns.scatterplot(
    x='News_Sentiment_1Yr',
    y='Patent_Count',
    size='Total_Funding_USD_M',
    data=df,
    hue='CompanyName',
    sizes=(100, 2000),
    legend=False
)

# Add labels and annotations
plt.title('The Innovation (Patents) vs. Hype (News Sentiment) Matrix', fontsize=16)
plt.xlabel('Market Hype (News Sentiment Score)')
plt.ylabel('Technical Innovation (Patent Count)')
plt.axhline(df['Patent_Count'].median(), color='grey', linestyle='--')
plt.axvline(df['News_Sentiment_1Yr'].median(), color='grey', linestyle='--')
plt.text(df['News_Sentiment_1Yr'].max(), df['Patent_Count'].median(), '  Stars', verticalalignment='bottom', horizontalalignment='right', color='darkgreen')
plt.text(df['News_Sentiment_1Yr'].min(), df['Patent_Count'].median(), '  Hidden Gems', verticalalignment='bottom', horizontalalignment='left', color='darkblue')
for i in range(df.shape[0]):
    plt.text(df['News_Sentiment_1Yr'][i], df['Patent_Count'][i], df['CompanyName'][i], fontsize=9)

plt.show()
print("EDA Insight 2: Companies can be segmented. Our goal is to find the 'Hidden Gems' in the top-left quadrant.")


# =============================================================================
# Cell 6: Feature Engineering
# =============================================================================
# Normalize columns before combining them into scores
scaler = MinMaxScaler(feature_range=(0, 100))

# Engineer 'Tech_Moat_Score'
df['Tech_Moat_Score'] = scaler.fit_transform(df[['Patent_Count', 'Patent_Citation_Velocity']]).mean(axis=1)

# Engineer 'Momentum_Score'
# Invert 'Time_Since_Last_Funding' because less time is better
df['Time_Score'] = 1 / df['Time_Since_Last_Funding']
df['Momentum_Score'] = scaler.fit_transform(df[['Employee_Growth_6Mo', 'News_Sentiment_1Yr', 'Time_Score']]).mean(axis=1)

print("\nEngineered features created:")
print(df[['CompanyName', 'Tech_Moat_Score', 'Momentum_Score']].round(1))


# =============================================================================
# Cell 7: Building the "Chimera" Model (Simplified Example)
# =============================================================================
# For this demonstration, we'll create a synthetic target variable.
# Let's assume the "best" targets are those with high moat and high momentum.
df['is_top_target'] = ((df['Tech_Moat_Score'] > 50) & (df['Momentum_Score'] > 50)).astype(int)

# Define features (X) and target (y)
features = ['Tech_Moat_Score', 'Momentum_Score', 'Investor_Quality_Score', 'Leadership_Pedigree_Score']
X = df[features]
y = df['is_top_target']

# Initialize and train a RandomForest model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X, y)

print(f"\nModel trained successfully on {len(X)} companies.")
print(f"Number of top targets identified in sample: {y.sum()}")


# =============================================================================
# Cell 8: Generating the Final "Synergy & Success Score"
# =============================================================================
# Use the model to predict the probability of being a top target
# This probability will serve as our final score.
df['Synergy_Success_Score'] = (model.predict_proba(X)[:, 1] * 100).round(1)

# Sort the companies by their score
final_recommendations = df.sort_values(by='Synergy_Success_Score', ascending=False)

print("\n=================================================")
print("   PROJECT CHIMERA - FINAL RECOMMENDATIONS")
print("=================================================")
print(final_recommendations[['CompanyName', 'Synergy_Success_Score', 'Tech_Moat_Score', 'Momentum_Score']])
